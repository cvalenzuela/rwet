{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import keras\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from __future__ import unicode_literals # allows to use unicode strings\n",
    "import spacy\n",
    "import markov\n",
    "from random import choice, randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = load_model('models/metamorphosis.h5')\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "maxlen = 40\n",
    "text = open('source_text/gutenberg.txt').read().lower() # read the file and convert to lowercase \n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "# what position does each character exist at in the prev list\n",
    "char_indices = dict((c,i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i,c) for i,c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"continue our guns to see france and still nicer,” said madame de la scala, hum! 'arms: azure, its obscurity concerning which she have ever actually throb always right. one whom he in his own sovereign and commend the libyan floods overflowed with the whalemen call it. harriet also. i saw them of the square, too, got home at every moment there is far off. his amputated above all, and here comes to see them.... but no farther.” “what can give it was forced into the andras[65] the charwoman just wedged in your little there was never of the occasion served. he\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = markov.build_model(text, 1)\n",
    "\" \".join(markov.generate(model, 1, ['continue']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# helper function to sample an index from a probability array\n",
    "# This comes directly from\n",
    "# https://github.com/fchollet/keras/blob/master/examples/lstm_text_generation.py\n",
    "def sample(preds, temperature=0.6):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "turn right and e whole for their wort of his breakfasting the from the floo\n",
      "=====\n",
      "Turn right and e whole for their wort of his breakfasting the from the floo.\n"
     ]
    }
   ],
   "source": [
    "## sentence = 'alice was beggining to get very tired of'\n",
    "#sentence = 'sturn left andturn left andturn left and'\n",
    "initial_route = 'turn right and'\n",
    "# Grab diversity\n",
    "diversity = float(0.5)\n",
    "# how many chars to generate\n",
    "length = int(100)\n",
    "# Start with empty generated string\n",
    "generated = ''\n",
    "line = ''\n",
    "\n",
    "start_index = randint(0, len(text)-maxlen-1)\n",
    "\n",
    "while len(initial_route) < maxlen:\n",
    "    initial_route = initial_route + \" \" + text[start_index:start_index+maxlen]\n",
    "if len(initial_route) > maxlen:\n",
    "    initial_route = initial_route[:maxlen]\n",
    "\n",
    "sentence = initial_route\n",
    "\n",
    "for i in range(length):\n",
    "    # First vectorize the text we are feeding in\n",
    "    x = np.zeros((1, maxlen, len(chars)))\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[0, t, char_indices[char]] = 1.\n",
    "    # Then get a probability map of possible predictions of the next char\n",
    "    preds = model.predict(x, verbose=0)[0]\n",
    "    # Pick one\n",
    "    next_index = sample(preds, diversity)\n",
    "    # What character is it?\n",
    "    next_char = indices_char[next_index]\n",
    "    # Add it\n",
    "    generated += next_char\n",
    "    # Now feed in the previous sentence minus the first char plus the next char\n",
    "    sentence = sentence[1:] + next_char\n",
    "    # nlp for the sentence\n",
    "    line = ' '.join(initial_route.split()[:3]) + ' ' +' '.join(generated[40:].split())\n",
    "    \n",
    "print(line)\n",
    "print(\"=====\")\n",
    "doc = nlp(line)\n",
    "nouns = [item.text for item in doc if item.pos_ == 'NOUN']\n",
    "adjs = [item.text for item in doc if item.pos_ == 'ADJ']    \n",
    "line = line.partition(choice(nouns))[0] + choice(nouns) + '.'\n",
    "line = \" \".join(line.split()).capitalize()\n",
    "print(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
